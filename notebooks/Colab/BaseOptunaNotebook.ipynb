{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxnbnrRxT55M"
      },
      "source": [
        "# Base Notebook to Run Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7jfDX2wUKaS"
      },
      "source": [
        "## Notebook Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TEBzx7oEJu5",
        "outputId": "86e4a86e-e047-41e2-a21c-8ac15295f4ec"
      },
      "outputs": [],
      "source": [
        "!pip install uv\n",
        "!git clone https://github.com/jorgesilva2407/poc.git /gcr\n",
        "%cd /gcr\n",
        "!uv sync --no-dev --no-cache-dir\n",
        "!pip install \"optuna[database]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Depedencies\n",
        "- Import dependencies\n",
        "- Mount Google Drive\n",
        "- Define global variables\n",
        "    - Assert paths exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3898a022"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import subprocess\n",
        "from enum import Enum\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import optuna\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "TENSORBOARD_LOG_DIR = \"/content/drive/MyDrive/poc/tensorboard\"\n",
        "ARTIFACTS_LOG_DIR = \"/content/drive/MyDrive/poc/artifacts\"\n",
        "METRIC_FILE = \"/tmp/metric.json\"\n",
        "DATA_DIR = \"/content/drive/MyDrive/poc/data\"\n",
        "OPTUNA_DIR = \"/content/drive/MyDrive/poc/optuna\"\n",
        "\n",
        "os.makedirs(TENSORBOARD_LOG_DIR, exist_ok=True)\n",
        "os.makedirs(ARTIFACTS_LOG_DIR, exist_ok=True)\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(OPTUNA_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ugvFB5CXvdu"
      },
      "source": [
        "## Optuna Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Hyper Parameter Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucNq-4aAcJRP"
      },
      "outputs": [],
      "source": [
        "class HParamType(Enum):\n",
        "    LOGUNIFORM = \"loguniform\"\n",
        "    UNIFORM = \"uniform\"\n",
        "    INTEGER = \"integer\"\n",
        "    CATEGORICAL = \"categorical\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class HParam:\n",
        "    type: HParamType\n",
        "\n",
        "    def suggest(self, trial, name: str):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Categorical(HParam):\n",
        "    choices: list[int | float | str]\n",
        "\n",
        "    def __init__(self, choices: list[int | float | str]):\n",
        "        super().__init__(HParamType.CATEGORICAL)\n",
        "        self.choices = choices\n",
        "\n",
        "    def suggest(self, trial, name: str):\n",
        "        return trial.suggest_categorical(name, self.choices)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Uniform(HParam):\n",
        "    low: float\n",
        "    high: float\n",
        "\n",
        "    def __init__(self, low: float, high: float):\n",
        "        super().__init__(HParamType.UNIFORM)\n",
        "        self.low = low\n",
        "        self.high = high\n",
        "\n",
        "    def suggest(self, trial, name: str):\n",
        "        return trial.suggest_uniform(name, self.low, self.high)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LogUniform(HParam):\n",
        "    low: float\n",
        "    high: float\n",
        "\n",
        "    def __init__(self, low: float, high: float):\n",
        "        super().__init__(HParamType.LOGUNIFORM)\n",
        "        self.low = low\n",
        "        self.high = high\n",
        "\n",
        "    def suggest(self, trial, name: str):\n",
        "        return trial.suggest_loguniform(name, self.low, self.high)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Integer(HParam):\n",
        "    low: int\n",
        "    high: int\n",
        "\n",
        "    def __init__(self, low: int, high: int):\n",
        "        super().__init__(HParamType.INTEGER)\n",
        "        self.low = low\n",
        "        self.high = high\n",
        "\n",
        "    def suggest(self, trial, name: str):\n",
        "        return trial.suggest_int(name, self.low, self.high)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper Function to get a set of Hyper Parameters to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tedx7ojclgT"
      },
      "outputs": [],
      "source": [
        "def suggest_params(trial, search_space):\n",
        "    params = {}\n",
        "    for name, hparam in search_space.items():\n",
        "        params[name] = hparam.suggest(trial, name)\n",
        "    return params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpHztE6ydHdM"
      },
      "outputs": [],
      "source": [
        "def run_model(\n",
        "    model_name: str,\n",
        "    params: dict,\n",
        "    all_csv: str,\n",
        "    train_csv: str,\n",
        "    val_csv: str,\n",
        "    test_csv: str,\n",
        ") -> float:\n",
        "    cmd = [\n",
        "        \"uv\",\n",
        "        \"run\",\n",
        "        \"main.py\",\n",
        "        \"--model\",\n",
        "        model_name,\n",
        "        \"--logger\",\n",
        "        \"TensorBoard\",\n",
        "        \"--tensorboard-log-dir\",\n",
        "        TENSORBOARD_LOG_DIR,\n",
        "        \"--artifact-saver\",\n",
        "        \"Local\",\n",
        "        \"--optuna-metric-file\",\n",
        "        METRIC_FILE,\n",
        "        \"--local-artifacts-path\",\n",
        "        ARTIFACTS_LOG_DIR,\n",
        "        \"--experiment-tracker\",\n",
        "        \"Optuna\",\n",
        "        \"--batch-size\",\n",
        "        64,\n",
        "        \"--all-interactions-csv\",\n",
        "        all_csv,\n",
        "        \"--train-interactions-csv\",\n",
        "        train_csv,\n",
        "        \"--validation-interactions-csv\",\n",
        "        val_csv,\n",
        "        \"--test-interactions-csv\",\n",
        "        test_csv,\n",
        "    ]\n",
        "\n",
        "    for param, value in params.items():\n",
        "        cmd.extend([param, str(value)])\n",
        "\n",
        "    cmd = [str(c) for c in cmd]\n",
        "\n",
        "    print(\" \".join(cmd))\n",
        "\n",
        "    with subprocess.Popen(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "        bufsize=1,\n",
        "    ) as process:\n",
        "        for line in process.stdout:\n",
        "            print(line, end=\"\", flush=True)\n",
        "\n",
        "    metric = None\n",
        "    with open(METRIC_FILE, \"r\") as f:\n",
        "        metric = json.load(f)\n",
        "    return metric[\"value\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the Objective of the Optuna Study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UhCyg7k-S33"
      },
      "outputs": [],
      "source": [
        "def objective_factory(model_name: str, search_space: dict, dataset: str):\n",
        "    def objective(trial):\n",
        "        params = suggest_params(trial, search_space)\n",
        "\n",
        "        data_dir = Path(DATA_DIR) / dataset\n",
        "        all_csv = data_dir / \"all_interactions.csv\"\n",
        "        train_csv = data_dir / \"split\" / \"train.csv\"\n",
        "        val_csv = data_dir / \"split\" / \"val.csv\"\n",
        "        test_csv = data_dir / \"split\" / \"test_neg_samples.csv\"\n",
        "\n",
        "        paths = [data_dir, all_csv, train_csv, val_csv, test_csv]\n",
        "        missing_paths = [path for path in paths if not path.exists()]\n",
        "\n",
        "        if missing_paths:\n",
        "            raise ValueError(f\"Missing paths: {missing_paths}\")\n",
        "\n",
        "        result = run_model(model_name, params, all_csv, train_csv, val_csv, test_csv)\n",
        "        return result\n",
        "\n",
        "    return objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run an Optuna Study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vD8p1GiC_Luu"
      },
      "outputs": [],
      "source": [
        "def optimize_model(\n",
        "    model_name: str, search_space: dict, dataset: str, n_trials: int = 20\n",
        "):\n",
        "    db_path = Path(OPTUNA_DIR) / f\"{model_name}.db\"\n",
        "    study = optuna.create_study(\n",
        "        study_name=f\"{model_name}Optimization\",\n",
        "        direction=\"maximize\",\n",
        "        storage=f\"sqlite:///{db_path}\",\n",
        "        load_if_exists=True,\n",
        "        sampler=optuna.samplers.TPESampler(seed=42),\n",
        "    )\n",
        "\n",
        "    objective = objective_factory(model_name, search_space, dataset)\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "\n",
        "    print(\"\\nâœ… Optimization complete!\")\n",
        "    print(f\"Best value: {study.best_value}\")\n",
        "    print(f\"Best params: {study.best_params}\")\n",
        "\n",
        "    return study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Update the model, dataset and search space as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = \"your_model_name\"\n",
        "dataset = \"your_dataset_name\"\n",
        "search_space = {\n",
        "    \"--hparam1\": Categorical(choices=[\"option1\", \"option2\", \"option3\"]),\n",
        "    \"--hparam2\": Uniform(low=0.0, high=1.0),\n",
        "    \"--hparam3\": LogUniform(low=1e-5, high=1e-1),\n",
        "    \"--hparam4\": Integer(low=1, high=100),\n",
        "    \"--learning-rate\": LogUniform(low=1e-5, high=1e-2),\n",
        "    \"--weight-decay\": LogUniform(low=1e-6, high=1e-3),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimize_model(model, search_space, dataset, n_trials=20)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
