{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7122a825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import init_path\n",
    "\n",
    "init_path.init()\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from datasets.pointwise import PointwiseDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models.biased_svd import BiasedSVD\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"../runs/biased_svd\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75e6b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/processed/train.csv\")\n",
    "val_df = pd.read_csv(\"../data/processed/val.csv\")\n",
    "test_df = pd.read_csv(\"../data/processed/test.csv\")\n",
    "\n",
    "item_encoder = pkl.load(open(\"../data/processed/item_encoder.pkl\", \"rb\"))\n",
    "user_encoder = pkl.load(open(\"../data/processed/user_encoder.pkl\", \"rb\"))\n",
    "\n",
    "train_dataset = PointwiseDataset(train_df)\n",
    "val_dataset = PointwiseDataset(val_df)\n",
    "test_dataset = PointwiseDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92d8d70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiasedSVD(\n",
       "  (user_embedding): Embedding(57530, 64)\n",
       "  (item_embedding): Embedding(35123, 64)\n",
       "  (user_bias): Embedding(57530, 1)\n",
       "  (item_bias): Embedding(35123, 1)\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiasedSVD(len(user_encoder.classes_), len(item_encoder.classes_), 64)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8cbeed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69abad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b86b5175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training: 100%|██████████| 1415/1415 [00:23<00:00, 59.55it/s]\n",
      "Epoch 2/10 - Validation: 100%|██████████| 225/225 [00:01<00:00, 178.52it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 1415/1415 [00:23<00:00, 60.31it/s]\n",
      "Epoch 3/10 - Validation: 100%|██████████| 225/225 [00:01<00:00, 194.64it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 1415/1415 [00:24<00:00, 58.32it/s]\n",
      "Epoch 4/10 - Validation: 100%|██████████| 225/225 [00:01<00:00, 194.56it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 1415/1415 [00:23<00:00, 60.16it/s]\n",
      "Epoch 5/10 - Validation: 100%|██████████| 225/225 [00:01<00:00, 197.88it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 1415/1415 [00:23<00:00, 60.49it/s]\n",
      "Epoch 6/10 - Validation: 100%|██████████| 225/225 [00:01<00:00, 191.68it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 1415/1415 [00:24<00:00, 57.07it/s]\n",
      "Epoch 7/10 - Validation: 100%|██████████| 225/225 [00:01<00:00, 176.49it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 1415/1415 [00:23<00:00, 61.36it/s]\n",
      "Epoch 8/10 - Validation: 100%|██████████| 225/225 [00:01<00:00, 196.54it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 1415/1415 [00:25<00:00, 55.92it/s]\n",
      "Epoch 9/10 - Validation: 100%|██████████| 225/225 [00:01<00:00, 185.24it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 1415/1415 [00:27<00:00, 51.94it/s]\n",
      "Epoch 10/10 - Validation: 100%|██████████| 225/225 [00:01<00:00, 195.11it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 1415/1415 [00:26<00:00, 53.32it/s]\n",
      "Epoch 11/10 - Validation: 100%|██████████| 225/225 [00:01<00:00, 184.70it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for user_ids, item_ids, labels in tqdm.tqdm(\n",
    "        train_loader, desc=f\"Epoch {epoch}/{epochs} - Training\"\n",
    "    ):\n",
    "        user_ids = user_ids.to(device)\n",
    "        item_ids = item_ids.to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_ids, item_ids)\n",
    "        loss = model.loss(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * user_ids.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for user_ids, item_ids, labels in tqdm.tqdm(\n",
    "            val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\"\n",
    "        ):\n",
    "            user_ids = user_ids.to(device)\n",
    "            item_ids = item_ids.to(device)\n",
    "            labels = labels.float().to(device)\n",
    "\n",
    "            predictions = model(user_ids, item_ids)\n",
    "            loss = model.loss(predictions, labels)\n",
    "\n",
    "            val_loss += loss.item() * user_ids.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    writer.add_scalar(\"Loss/Validation\", val_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68395e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5925, Test AUC: 0.5881, Test Accuracy: 0.7313\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for user_ids, item_ids, targets in test_loader:\n",
    "        user_ids = user_ids.to(device)\n",
    "        item_ids = item_ids.to(device)\n",
    "        targets = targets.float().to(device)\n",
    "\n",
    "        predictions = model(user_ids, item_ids)\n",
    "        loss = model.loss(predictions, targets)\n",
    "        test_loss += loss.item() * user_ids.size(0)\n",
    "\n",
    "        preds = torch.sigmoid(predictions)\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_targets.append(targets.cpu())\n",
    "\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_targets = torch.cat(all_targets)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_auc = roc_auc_score(all_targets, all_preds)\n",
    "test_acc = accuracy_score(all_targets, (all_preds >= 0.5).int())\n",
    "\n",
    "print(\n",
    "    f\"Test Loss: {test_loss:.4f}, Test AUC: {test_auc:.4f}, Test Accuracy: {test_acc:.4f}\"\n",
    ")\n",
    "\n",
    "writer.add_scalar(\"Loss/test\", test_loss)\n",
    "writer.add_scalar(\"AUC/test\", test_auc)\n",
    "writer.add_scalar(\"Accuracy/test\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18407e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enhancedgcr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
